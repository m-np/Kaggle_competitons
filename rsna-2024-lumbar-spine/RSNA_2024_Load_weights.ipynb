{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Downloading model weights from wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os, gc, sys, copy, pickle\nfrom pathlib import Path\nimport glob\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nimport math\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom joblib import Parallel, delayed\nimport multiprocessing as mp\n\nimport albumentations as A\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.cuda.amp as amp\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\nfrom torch.utils.data import WeightedRandomSampler\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport timm\n\nimport cv2\ncv2.setNumThreads(0)\nimport PIL\nimport pydicom\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:19:03.267407Z","iopub.execute_input":"2024-07-07T20:19:03.268321Z","iopub.status.idle":"2024-07-07T20:19:03.278947Z","shell.execute_reply.started":"2024-07-07T20:19:03.268283Z","shell.execute_reply":"2024-07-07T20:19:03.277903Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"WANDB_API_KEY\")\nwandb.login(key=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:19:13.437079Z","iopub.execute_input":"2024-07-07T20:19:13.438263Z","iopub.status.idle":"2024-07-07T20:19:15.994240Z","shell.execute_reply.started":"2024-07-07T20:19:13.438225Z","shell.execute_reply":"2024-07-07T20:19:15.993216Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def seeding(SEED):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    torch.manual_seed(SEED)\n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(SEED)\n        torch.cuda.manual_seed_all(SEED)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n#     os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n#     tf.random.set_seed(SEED)\n#     keras.utils.set_random_seed(seed=SEED)\n    print('seeding done!!!')\n\ndef flush():\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.reset_peak_memory_stats()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:19:23.716486Z","iopub.execute_input":"2024-07-07T20:19:23.717241Z","iopub.status.idle":"2024-07-07T20:19:23.724512Z","shell.execute_reply.started":"2024-07-07T20:19:23.717207Z","shell.execute_reply":"2024-07-07T20:19:23.723198Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"CONFIG = dict(\n    project_name = \"RSNA-2024-Lumbar-Spine-Classification-Torch-RZoro\",\n    artifact_name = \"rsnaEffNetModel\",\n    load_kernel = None,\n    load_last = True,\n    n_folds = 5,\n    backbone = \"efficientnet_b0.ra_in1k\", # tf_efficientnetv2_s_in21ft1k\n    img_size = 384,\n    n_slice_per_c = 16,\n    in_chans = 3,\n\n    drop_rate = 0.,\n    drop_rate_last = 0.3,\n    drop_path_rate = 0.,\n    p_mixup = 0.5,\n    p_rand_order_v1 = 0.2,\n    lr = 4e-4, # 1e-3, 8e-4, 5e-4, 4e-4\n\n    out_dim = 3,\n    epochs = 50,\n    batch_size = 16,\n#     patience = 7,\n    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\",\n    seed = 2024,\n    log_wandb = True,\n    with_clip = True,\n)\n\nCONFIG['patience'] = math.ceil(0.2 * CONFIG['epochs'])\n\nseeding(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:19:41.220792Z","iopub.execute_input":"2024-07-07T20:19:41.221603Z","iopub.status.idle":"2024-07-07T20:19:41.231831Z","shell.execute_reply.started":"2024-07-07T20:19:41.221568Z","shell.execute_reply":"2024-07-07T20:19:41.230633Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"seeding done!!!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"class TimmModel(nn.Module):\n    def __init__(self, backbone, pretrained=False):\n        super(TimmModel, self).__init__()\n\n        self.encoder = timm.create_model(\n            backbone,\n            num_classes=CONFIG[\"out_dim\"],\n            features_only=False,\n            drop_rate=CONFIG[\"drop_rate\"],\n            drop_path_rate=CONFIG[\"drop_path_rate\"],\n            pretrained=pretrained\n        )\n\n        if 'efficient' in backbone:\n            hdim = self.encoder.conv_head.out_channels\n            self.encoder.classifier = nn.Identity()\n        elif 'convnext' in backbone:\n            hdim = self.encoder.head.fc.in_features\n            self.encoder.head.fc = nn.Identity()\n\n\n        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=CONFIG[\"drop_rate\"], bidirectional=True, batch_first=True)\n        self.head = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.Dropout(CONFIG[\"drop_rate_last\"]),\n            nn.LeakyReLU(0.1),\n            nn.Linear(256, CONFIG[\"out_dim\"]),\n        )\n\n    def forward(self, x):\n        feat = self.encoder(x)\n        feat, _ = self.lstm(feat)\n        feat = self.head(feat)\n        return feat","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:20:06.973010Z","iopub.execute_input":"2024-07-07T20:20:06.973455Z","iopub.status.idle":"2024-07-07T20:20:06.983464Z","shell.execute_reply.started":"2024-07-07T20:20:06.973407Z","shell.execute_reply":"2024-07-07T20:20:06.982308Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Cross validation","metadata":{}},{"cell_type":"code","source":"DATA_PATH = Path(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification\")\nos.listdir(DATA_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:20:36.695695Z","iopub.execute_input":"2024-07-07T20:20:36.696103Z","iopub.status.idle":"2024-07-07T20:20:36.705085Z","shell.execute_reply.started":"2024-07-07T20:20:36.696070Z","shell.execute_reply":"2024-07-07T20:20:36.704055Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['sample_submission.csv',\n 'train_images',\n 'train_series_descriptions.csv',\n 'train.csv',\n 'train_label_coordinates.csv',\n 'test_series_descriptions.csv',\n 'test_images']"},"metadata":{}}]},{"cell_type":"code","source":"train_main = pd.read_csv(DATA_PATH/\"train.csv\")\ntrain_desc = pd.read_csv(DATA_PATH/\"train_series_descriptions.csv\")\ntrain_label_coordinates = pd.read_csv(DATA_PATH/\"train_label_coordinates.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:20:42.367758Z","iopub.execute_input":"2024-07-07T20:20:42.368485Z","iopub.status.idle":"2024-07-07T20:20:42.522666Z","shell.execute_reply.started":"2024-07-07T20:20:42.368449Z","shell.execute_reply":"2024-07-07T20:20:42.521718Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Define function to reshape a single row of the DataFrame\ndef reshape_row(row):\n    data = {'study_id': [], 'condition': [], 'level': [], 'severity': []}\n    \n    for column, value in row.items():\n        if column not in ['study_id', 'series_id', 'instance_number', 'x', 'y', 'series_description']:\n            parts = column.split('_')\n            condition = ' '.join([word.capitalize() for word in parts[:-2]])\n            level = parts[-2].capitalize() + '/' + parts[-1].capitalize()\n            data['study_id'].append(row['study_id'])\n            data['condition'].append(condition)\n            data['level'].append(level)\n            data['severity'].append(value)\n    \n    return pd.DataFrame(data)\n\n# Reshape the DataFrame for all rows\nnew_train_df = pd.concat([reshape_row(row) for _, row in train_main.iterrows()], ignore_index=True)\n\n# Display the first few rows of the reshaped dataframe\nnew_train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:20:48.424171Z","iopub.execute_input":"2024-07-07T20:20:48.425145Z","iopub.status.idle":"2024-07-07T20:20:49.810673Z","shell.execute_reply.started":"2024-07-07T20:20:48.425110Z","shell.execute_reply":"2024-07-07T20:20:49.809601Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   study_id              condition  level     severity\n0   4003253  Spinal Canal Stenosis  L1/L2  Normal/Mild\n1   4003253  Spinal Canal Stenosis  L2/L3  Normal/Mild\n2   4003253  Spinal Canal Stenosis  L3/L4  Normal/Mild\n3   4003253  Spinal Canal Stenosis  L4/L5  Normal/Mild\n4   4003253  Spinal Canal Stenosis  L5/S1  Normal/Mild","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>condition</th>\n      <th>level</th>\n      <th>severity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L1/L2</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L2/L3</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L3/L4</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L4/L5</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L5/S1</td>\n      <td>Normal/Mild</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Merge the dataframes on the common columns\nmerged_df = pd.merge(new_train_df, train_label_coordinates, on=['study_id', 'condition', 'level'], how='inner')\nfinal_merged_df = pd.merge(merged_df, train_desc, on=['series_id','study_id'], how='inner')\n\n# Create the row_id column\nfinal_merged_df['row_id'] = (\n    final_merged_df['study_id'].astype(str) + '_' +\n    final_merged_df['condition'].str.lower().str.replace(' ', '_') + '_' +\n    final_merged_df['level'].str.lower().str.replace('/', '_')\n)\n\n# Create the image_path column\nfinal_merged_df['image_path'] = (\n    f'{str(DATA_PATH)}/train_images/' + \n    final_merged_df['study_id'].astype(str) + '/' +\n    final_merged_df['series_id'].astype(str) + '/' +\n    final_merged_df['instance_number'].astype(str) + '.dcm'\n)\n\nfinal_merged_df['severity'] = final_merged_df['severity'].map(\n    {'Normal/Mild': 'normal_mild', 'Moderate': 'moderate', 'Severe': 'severe'}\n)\n\ntrain_data = final_merged_df.copy()\n# Display the updated dataframe\ntrain_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:20:57.329886Z","iopub.execute_input":"2024-07-07T20:20:57.330277Z","iopub.status.idle":"2024-07-07T20:20:57.613744Z","shell.execute_reply.started":"2024-07-07T20:20:57.330244Z","shell.execute_reply":"2024-07-07T20:20:57.612664Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   study_id              condition  level     severity  series_id  \\\n0   4003253  Spinal Canal Stenosis  L1/L2  normal_mild  702807833   \n1   4003253  Spinal Canal Stenosis  L2/L3  normal_mild  702807833   \n2   4003253  Spinal Canal Stenosis  L3/L4  normal_mild  702807833   \n3   4003253  Spinal Canal Stenosis  L4/L5  normal_mild  702807833   \n4   4003253  Spinal Canal Stenosis  L5/S1  normal_mild  702807833   \n\n   instance_number           x           y series_description  \\\n0                8  322.831858  227.964602   Sagittal T2/STIR   \n1                8  320.571429  295.714286   Sagittal T2/STIR   \n2                8  323.030303  371.818182   Sagittal T2/STIR   \n3                8  335.292035  427.327434   Sagittal T2/STIR   \n4                8  353.415929  483.964602   Sagittal T2/STIR   \n\n                                row_id  \\\n0  4003253_spinal_canal_stenosis_l1_l2   \n1  4003253_spinal_canal_stenosis_l2_l3   \n2  4003253_spinal_canal_stenosis_l3_l4   \n3  4003253_spinal_canal_stenosis_l4_l5   \n4  4003253_spinal_canal_stenosis_l5_s1   \n\n                                          image_path  \n0  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n1  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n2  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n3  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n4  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>condition</th>\n      <th>level</th>\n      <th>severity</th>\n      <th>series_id</th>\n      <th>instance_number</th>\n      <th>x</th>\n      <th>y</th>\n      <th>series_description</th>\n      <th>row_id</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L1/L2</td>\n      <td>normal_mild</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>322.831858</td>\n      <td>227.964602</td>\n      <td>Sagittal T2/STIR</td>\n      <td>4003253_spinal_canal_stenosis_l1_l2</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L2/L3</td>\n      <td>normal_mild</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>320.571429</td>\n      <td>295.714286</td>\n      <td>Sagittal T2/STIR</td>\n      <td>4003253_spinal_canal_stenosis_l2_l3</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L3/L4</td>\n      <td>normal_mild</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>323.030303</td>\n      <td>371.818182</td>\n      <td>Sagittal T2/STIR</td>\n      <td>4003253_spinal_canal_stenosis_l3_l4</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L4/L5</td>\n      <td>normal_mild</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>335.292035</td>\n      <td>427.327434</td>\n      <td>Sagittal T2/STIR</td>\n      <td>4003253_spinal_canal_stenosis_l4_l5</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L5/S1</td>\n      <td>normal_mild</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>353.415929</td>\n      <td>483.964602</td>\n      <td>Sagittal T2/STIR</td>\n      <td>4003253_spinal_canal_stenosis_l5_s1</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Define a function to check if a path exists\ndef check_exists(path):\n    return os.path.exists(path)\n\n# Define a function to check if a study ID directory exists\ndef check_study_id(row):\n    study_id = row['study_id']\n    path = f'{str(DATA_PATH)}/train_images/{study_id}'\n    return check_exists(path)\n\n# Define a function to check if a series ID directory exists\ndef check_series_id(row):\n    study_id = row['study_id']\n    series_id = row['series_id']\n    path = f'{str(DATA_PATH)}/train_images/{study_id}/{series_id}'\n    return check_exists(path)\n\n# Define a function to check if an image file exists\ndef check_image_exists(row):\n    image_path = row['image_path']\n    return check_exists(image_path)\n\n# Apply the functions to the train_data dataframe\ntrain_data['study_id_exists'] = train_data.progress_apply(check_study_id, axis=1)\ntrain_data['series_id_exists'] = train_data.progress_apply(check_series_id, axis=1)\ntrain_data['image_exists'] = train_data.progress_apply(check_image_exists, axis=1)\n\n# Filter train_data\ntrain_data = train_data[(train_data['study_id_exists']) & (train_data['series_id_exists']) & (train_data['image_exists'])]","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:21:04.374568Z","iopub.execute_input":"2024-07-07T20:21:04.374963Z","iopub.status.idle":"2024-07-07T20:21:59.195742Z","shell.execute_reply.started":"2024-07-07T20:21:04.374934Z","shell.execute_reply":"2024-07-07T20:21:59.194674Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48692 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f3186ab8e24475baacf25a9072cd19b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48692 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5694752d7cb5409b9cb710eee0009a2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48692 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af35a2ea328b493ab43fbcd8d387428c"}},"metadata":{}}]},{"cell_type":"code","source":"label2id = {v: i for i, v in enumerate(train_data['severity'].unique())}\nid2label = {v:k for k,v in label2id.items()}\ntrain_data['target'] = train_data['severity'].map(label2id)\ntrain_data = train_data.dropna(subset=['severity']).reset_index(drop=True)\n\n# series2id = {v:i for i, v in enumerate(train_data['series_description'].unique().tolist())}\n# id2series = {v:k for k,v in series2id.items()}\n# train_data['series2id'] = train_desc['series_description'].map(series2id)\n# train_data = train_data.dropna(subset=['series2id']).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:21:59.198013Z","iopub.execute_input":"2024-07-07T20:21:59.198519Z","iopub.status.idle":"2024-07-07T20:21:59.233071Z","shell.execute_reply.started":"2024-07-07T20:21:59.198480Z","shell.execute_reply":"2024-07-07T20:21:59.232221Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def load_dicom(path):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:21:59.234511Z","iopub.execute_input":"2024-07-07T20:21:59.235147Z","iopub.status.idle":"2024-07-07T20:21:59.241289Z","shell.execute_reply.started":"2024-07-07T20:21:59.235110Z","shell.execute_reply":"2024-07-07T20:21:59.240225Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe, transform=None, label_name='target'):\n        self.dataframe = dataframe\n        self.transform = transform\n        self.label = dataframe.loc[:, label_name]\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        image_path = self.dataframe['image_path'][index]\n        image = load_dicom(image_path)  # Define this function to load your DICOM images\n        target = self.dataframe['target'][index]\n        \n        if self.transform:\n            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n            image = self.transform(image=image)['image']\n            image = image.transpose(2, 0, 1).astype(np.float32) / 255.\n\n        return image, torch.tensor(target).float()\n    \n    def get_labels(self):\n        return self.label","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:21:59.243315Z","iopub.execute_input":"2024-07-07T20:21:59.243761Z","iopub.status.idle":"2024-07-07T20:21:59.252199Z","shell.execute_reply.started":"2024-07-07T20:21:59.243732Z","shell.execute_reply":"2024-07-07T20:21:59.251227Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_transforms(height, width):\n    train_tsfm = A.Compose([\n        # Geometric augmentations\n#         A.Perspective(p=0.5),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n#         A.RandomRotate90(p=0.5),\n        A.Rotate(-30, 30, p=0.5),\n        \n        A.Resize(height=height, width=width),\n    ])\n    \n    valid_tsfm = A.Compose([\n        A.Resize(height=height, width=width),\n    ])\n    return {\"train\": train_tsfm, \"eval\": valid_tsfm}\n\ndef get_dataloaders(data, cfg, split=\"train\"):\n    img_size = cfg['img_size']\n    height, width = img_size, img_size\n    tsfm = get_transforms(height=height, width=width)\n    if split == 'train':\n        tr_tsfm = tsfm['train']\n        ds = CustomDataset(data, transform=tr_tsfm)\n        labels = ds.get_labels()\n#         class_weights = torch.tensor(compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels))\n        class_weights = torch.tensor([1, 2, 4])\n        samples_weights = class_weights[labels]\n#         print(class_weights)\n        sampler = WeightedRandomSampler(weights=samples_weights, \n                                        num_samples=len(samples_weights), \n                                        replacement=True)\n\n        dls = DataLoader(ds, \n                         batch_size=cfg['batch_size'], \n                         sampler=sampler, \n                         num_workers=os.cpu_count(), \n                         drop_last=True, \n                         pin_memory=True)\n        \n    elif split == 'valid' or split == 'test':\n        eval_tsfm = tsfm['eval']\n        ds = CustomDataset(data, transform=eval_tsfm)\n        dls = DataLoader(ds, \n                         batch_size=2*cfg['batch_size'], \n                         shuffle=False, \n                         num_workers=os.cpu_count(), \n                         drop_last=False, \n                         pin_memory=True)\n    else:\n        raise Exception(\"Split should be 'train' or 'valid' or 'test'!!!\")\n    return dls","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:21:59.253703Z","iopub.execute_input":"2024-07-07T20:21:59.254251Z","iopub.status.idle":"2024-07-07T20:21:59.268168Z","shell.execute_reply.started":"2024-07-07T20:21:59.254215Z","shell.execute_reply":"2024-07-07T20:21:59.267241Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn import model_selection\n\nkfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2024)\nx = train_data.index.values\ny = train_data['target'].values.astype(int)\n# g = train_data['series2id'].values.astype(int)\n\ntrain_data['fold'] = -1\nfor fold, (tr_idx, val_idx) in enumerate(kfold.split(x,y)):\n    train_data.loc[val_idx, 'fold'] = fold\n    \ntrain_data['fold'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:21:59.269366Z","iopub.execute_input":"2024-07-07T20:21:59.269679Z","iopub.status.idle":"2024-07-07T20:21:59.307657Z","shell.execute_reply.started":"2024-07-07T20:21:59.269653Z","shell.execute_reply":"2024-07-07T20:21:59.306634Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"fold\n1    9732\n0    9732\n4    9731\n3    9731\n2    9731\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"FLIPS = [None, [-1], [-2], [-2, -1]]\n\ndef inference_loop(model, loader):\n    model.to(CONFIG[\"device\"])\n    model.eval()\n    preds = np.empty((0, 3))\n    with torch.no_grad():\n        for batch in tqdm(loader):\n            images, labels = batch\n            images = images.to(CONFIG[\"device\"], non_blocking=True)\n            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n#                 logits = model(images.to(torch.float32))\n                logits = model(images)\n                logits = logits.softmax(dim=-1)\n                preds = np.concatenate([preds, logits.detach().cpu().numpy()])\n#     np.save('preds.npy', preds)\n    return preds\n\n\n\ndef tta_inference_loop(model, loader):\n    model.to(CONFIG[\"device\"])\n    model.eval()\n    preds = np.empty((0, 3))\n    with torch.no_grad():\n        for batch in tqdm(loader):\n            images, labels = batch\n            images = images.to(CONFIG[\"device\"], non_blocking=True)\n            pred_tta = []\n            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n                for f in FLIPS:\n                    logits = model(torch.flip(images, f) if f is not None else images)\n                    logits = logits.softmax(dim=-1)\n                    pred_tta.append(logits.detach().cpu().numpy())\n#                 preds = np.concatenate([preds, logits.detach().cpu().numpy()])\n                preds = np.concatenate([preds, np.mean(pred_tta, 0)])\n#     np.save('preds.npy', preds)\n    return preds","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:21:59.309051Z","iopub.execute_input":"2024-07-07T20:21:59.309379Z","iopub.status.idle":"2024-07-07T20:21:59.319858Z","shell.execute_reply.started":"2024-07-07T20:21:59.309342Z","shell.execute_reply":"2024-07-07T20:21:59.318715Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import wandb\nrun = wandb.init()\nartifact = run.use_artifact('mandar4tech/RSNA-2024-Lumbar-Spine-Classification-Torch-RZoro/rsnaEffNetModel_0:v5', type='model')\nartifact_dir = artifact.download()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:24:21.623737Z","iopub.execute_input":"2024-07-07T20:24:21.624549Z","iopub.status.idle":"2024-07-07T20:24:43.896945Z","shell.execute_reply.started":"2024-07-07T20:24:21.624510Z","shell.execute_reply":"2024-07-07T20:24:43.895645Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmandar4tech\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240707_202421-9fee04nk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mandar4tech/uncategorized/runs/9fee04nk' target=\"_blank\">whole-armadillo-1</a></strong> to <a href='https://wandb.ai/mandar4tech/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mandar4tech/uncategorized' target=\"_blank\">https://wandb.ai/mandar4tech/uncategorized</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mandar4tech/uncategorized/runs/9fee04nk' target=\"_blank\">https://wandb.ai/mandar4tech/uncategorized/runs/9fee04nk</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n","output_type":"stream"}]},{"cell_type":"code","source":"# # checkpoints = glob.glob(f\"{artifact_dir}/*.ckpt\")[0]\n# # lit_model2 = LumbarLightningModel2.load_from_checkpoint(checkpoints)\n# # torch.save(lit_model2.model.state_dict(), \"model_weights.pth\")\n# # weights_path = \"/kaggle/working/model_weights.pth\"\nmodel = TimmModel(backbone=CONFIG[\"backbone\"], pretrained=False)\nweights_path = glob.glob(f\"{artifact_dir}/*.pth\")[0]\nweights = torch.load(weights_path, map_location=torch.device(\"cpu\"))\nmodel.load_state_dict(weights)\ntorch.save(model.state_dict(), \"model_weights.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T20:24:50.452469Z","iopub.execute_input":"2024-07-07T20:24:50.453537Z","iopub.status.idle":"2024-07-07T20:24:51.590969Z","shell.execute_reply.started":"2024-07-07T20:24:50.453500Z","shell.execute_reply":"2024-07-07T20:24:51.589918Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}